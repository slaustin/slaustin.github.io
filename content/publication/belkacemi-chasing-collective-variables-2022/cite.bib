@article{belkacemiChasingCollectiveVariables2022,
 abstract = {Free energy biasing methods have proven to be powerful tools to accelerate the simulation of important conformational changes of molecules by modifying the sampling measure. However, most of these methods rely on the prior knowledge of low-dimensional slow degrees of freedom, i.e., collective variables (CVs). Alternatively, such CVs can be identified using machine learning (ML) and dimensionality reduction algorithms. In this context, approaches where the CVs are learned in an iterative way using adaptive biasing have been proposed: At each iteration, the learned CV is used to perform free energy adaptive biasing to generate new data and learn a new CV. In this paper, we introduce a new iterative method involving CV learning with autoencoders: Free Energy Biasing and Iterative Learning with AutoEncoders (FEBILAE). Our method includes a reweighting scheme to ensure that the learning model optimizes the same loss at each iteration and achieves CV convergence. Using the alanine dipeptide system and the solvated chignolin mini-protein system as examples, we present results of our algorithm using the extended adaptive biasing force as the free energy adaptive biasing method.},
 archiveprefix = {arXiv},
 author = {Belkacemi, Zineb and Gkeka, Paraskevi and Leli√®vre, Tony and Stoltz, Gabriel},
 doi = {10.1021/acs.jctc.1c00415},
 eprint = {2104.11061},
 file = {/Users/stevenaustin/Zotero/storage/YUBCH78J/Chasing Collective Variables Using Autoencoders and BiasedTrajectories.pdf},
 issn = {15499626},
 journal = {Journal of Chemical Theory and Computation},
 number = {1},
 pages = {59--78},
 pmid = {34965117},
 publisher = {American Chemical Society},
 title = {Chasing Collective Variables Using Autoencoders and Biased Trajectories},
 volume = {18},
 year = {2022}
}
